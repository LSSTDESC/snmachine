{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indoor-section",
   "metadata": {},
   "source": [
    "# Train a Classifier\n",
    "\n",
    "In this notebook we train a Gradient Boosting Decision Tree (GBDT) classifier using the implementation of the package [LightGBM](https://lightgbm.readthedocs.io/en/latest/).\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import Packages](#imports)\n",
    "2. [Load Features](#loadFeatures)\n",
    "3. [Generate Classifier](#generateClassifier)\n",
    "    1. [Untrained Classifier](#createClassifier)\n",
    "    2. [Train Classifier](#trainClassifier)\n",
    "    3. [Save the Classifier Instance](#saveClassifier)\n",
    "\n",
    "## 1. Import Packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modern-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "destroyed-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "british-seeker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/calves/.conda/envs/snmachine/lib/python3.7/site-packages/dask/array/numpy_compat.py:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.divide(0.4, 1, casting=\"unsafe\", dtype=np.float),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'pymultinest'\n",
      "\n",
      "                PyMultinest not found. If you would like to use, please install\n",
      "                Mulitnest with 'sh install/multinest_install.sh; source\n",
      "                install/setup.sh'\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "from snmachine import snclassifier\n",
    "from utils.plasticc_pipeline import get_directories, load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "single-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('always', DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "drawn-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False  # enable autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nearby-regulation",
   "metadata": {},
   "source": [
    "## 2. Load Features<a name=\"loadFeatures\"></a>\n",
    "\n",
    "First, **write** the path to the folder that contains the features and the labels of the events (`path_saved_features`). These quantities were calculated and saved in [5_feature_extraction](5_feature_extraction.ipynb).\n",
    "\n",
    "### 2.1. Features Path<a name=\"pathFeatures\"></a>\n",
    "\n",
    "**<font color=Orange>A)</font>** Obtain path from folder structure.\n",
    "\n",
    "If you created a folder structure, you can obtain the path from there. **Write** the name of the folder in `analysis_name`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deadly-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_name = 'example_dataset_aug' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "urban-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../snmachine/example_data'\n",
    "\n",
    "directories = get_directories(folder_path, analysis_name) \n",
    "path_saved_features = directories['features_directory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-plenty",
   "metadata": {},
   "source": [
    "**<font color=Orange>B)</font>** Directly **write** where you saved the files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-volume",
   "metadata": {},
   "source": [
    "```python\n",
    "folder_path = '../snmachine/example_data'\n",
    "path_saved_features = folder_path\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-violation",
   "metadata": {},
   "source": [
    "### 2.2. Load<a name=\"load\"></a>\n",
    "\n",
    "Then, load the features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "annual-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_pickle(os.path.join(path_saved_features, 'features.pckl'))  # features\n",
    "y = pd.read_pickle(os.path.join(path_saved_features, 'data_labels.pckl'))  # class label of each event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-teach",
   "metadata": {},
   "source": [
    "**<font color=Orange>A)</font>** If the dataset is not augmented, skip **<font color=Orange>B)</font>**.\n",
    "\n",
    "\n",
    "**<font color=Orange>B)</font>** If the dataset is augmented, load the augmented dataset.\n",
    "\n",
    "In order to avoid information leaks during the classifier optimization, all synthetic events generated by the training set augmentation which derived from the same original event must be placed in the same cross-validation fold. \n",
    "\n",
    "First, **write** in `data_file_name` the name of the file where your dataset is saved.\n",
    "\n",
    "In this notebook we use the dataset saved in [4_augment_data](4_augment_data.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "alike-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = 'example_dataset_aug.pckl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-mediterranean",
   "metadata": {},
   "source": [
    "Then, load the augmented dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "inappropriate-portfolio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening from binary pickle\n",
      "Dataset loaded from pickle file as: <snmachine.sndata.PlasticcData object at 0x7ff03b07d290>\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(folder_path, data_file_name)\n",
    "dataset = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "active-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = dataset.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-financing",
   "metadata": {},
   "source": [
    "## 3. Generate Classifier<a name=\"generateClassifier\"></a>\n",
    "\n",
    "### 3.1. Untrained Classifier<a name=\"createClassifier\"></a>\n",
    "\n",
    "Start by creating a classifier. For that **choose**: \n",
    "\n",
    "- classifier type: `snmachine` contains the following classifiers\n",
    "    * [LightGBM](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html?highlight=classifier) classifier - `snclassifier.LightGBMClassifier`\n",
    "    * Boosted decision trees - `snclassifier.BoostDTClassifier`\n",
    "    * Boosted random forests - `snclassifier.BoostRFClassifier`\n",
    "    * K-nearest neighbors vote - `snclassifier.KNNClassifier`\n",
    "    * Support vector machine - `snclassifier.SVMClassifier`\n",
    "    * Multi-layer Perceptron classifier of a Neural Network - `snclassifier.NNClassifier`\n",
    "    * Random forest - `snclassifier.RFClassifier`\n",
    "    * Decision tree - `snclassifier.DTClassifier`\n",
    "    * Gaussian Naive Bayes - `snclassifier.NBClassifier`\n",
    "- `random_seed`: this allows reproducible results (**<font color=green>optional</font>**).\n",
    "- `classifier_name`: name under which the classifier is saved (**<font color=green>optional</font>**).\n",
    "- `**kwargs`: optional keywords to pass arguments into the underlying classifier; see the docstring in each classifier for more information (**<font color=green>optional</font>**).\n",
    "\n",
    "Here we chose a LightGBM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "innocent-yacht",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created classifier of type: LGBMClassifier(random_state=42).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_instance = snclassifier.LightGBMClassifier(classifier_name='our_classifier', random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-instruction",
   "metadata": {},
   "source": [
    "### 3.2. Train Classifier<a name=\"trainClassifier\"></a>\n",
    "\n",
    "We can now train and use the classifier generated above or optimise it beforehand. In general, it is important to optimise the classifier hyperparameters.\n",
    "\n",
    "If you do not want to optimise the classifier, **run** **<font color=Orange>A)</font>**.\n",
    "\n",
    "**<font color=Orange>A)</font>** Train unoptimised classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-qatar",
   "metadata": {},
   "source": [
    "```python\n",
    "classifier.fit(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-mountain",
   "metadata": {},
   "source": [
    "If you want to optimise the classifier, run **<font color=Orange>B)</font>**.\n",
    "\n",
    "**<font color=Orange>B)</font>** Optimise and train classifier.\n",
    "\n",
    "For that, **choose**:\n",
    "- `param_grid`: parameter grid containing the hyperparameters names and lists of their possible settings as values. If none is provided, the code uses a default parameter grid. (**<font color=green>optional</font>**)\n",
    "- `scoring`: metric used to evaluate the predictions on the validation sets and write it in `scoring`. \n",
    "    * `snmachine` contains the `'auc'` and the PLAsTiCC `'logloss'` costum metrics. For more details about these, see `snclassifier.logloss_score` and `snclassifier.auc_score`, respectively.\n",
    "    * Additionally, you can choose a different metric from the list in [Scikit-learn](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) or create your own (see [`sklearn.model_selection._search.GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) for details).\n",
    "- `number_cv_folds`: number of folds for cross-validation. By default it is 5. (**<font color=green>optional</font>**)\n",
    "- `metadata`: metadata of the events with which to train the classifier. This ensures all synthetic events generated by the training set augmentation that were derived from the same original event are placed in the same cross-validation fold. (**<font color=green>optional</font>**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "hired-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation for an augmented dataset.\n",
      "The optimisation takes 0.892s.\n"
     ]
    }
   ],
   "source": [
    "param_grid={'learning_rate': [.1, .25, .5]}\n",
    "\n",
    "classifier_instance.optimise(X, y, param_grid=param_grid, scoring='logloss', \n",
    "                             number_cv_folds=5, metadata=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-murray",
   "metadata": {},
   "source": [
    "The classifier is optimised and its optimised hyperparameters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "recovered-parallel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(random_state=42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_instance.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "certified-sherman",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_instance.grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "express-warren",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'our_classifier'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_instance.classifier_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-attention",
   "metadata": {},
   "source": [
    "### 3.3. Save the Classifier Instance<a name=\"saveClassifier\"></a>\n",
    "\n",
    "**Write** in `path_saved_classifier` the path to the folder where to save the trained classifier instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "breeding-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_classifier = directories['classifications_directory']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-lunch",
   "metadata": {},
   "source": [
    "Save the classifier instance (which includes the grid search used to optimise the classifier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "false-frontier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier saved in ../snmachine/example_data/example_dataset_aug/classifications/our_classifier.pck .\n"
     ]
    }
   ],
   "source": [
    "classifier_instance.save_classifier(path_saved_classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-macedonia",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)\n",
    "\n",
    "*Previous notebook:* [5_feature_extraction](5_feature_extraction.ipynb)\n",
    "\n",
    "**Next notebook:** [7_classify_test](7_classify_test.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
