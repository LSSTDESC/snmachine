{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "temporal-appendix",
   "metadata": {},
   "source": [
    "# Augment dataset\n",
    "\n",
    "In this notebook we exemplify how to augment a dataset. This is tipically done to increase the number and/or representativity of trainining sets.\n",
    "\n",
    "#### Index<a name=\"index\"></a>\n",
    "1. [Import Packages](#imports)\n",
    "2. [Load Dataset](#loadData)\n",
    "    1. [GP Path](#oriGpPath)\n",
    "3. [Augment Dataset](#augData)\n",
    "    1. [Choose the Events to Augment](#chooseEvent)\n",
    "    2. [Choose the Redshift for Augmented Events](#chooseZ)\n",
    "    3. [Choose the Photometric Redshift](#choosePhotoZ)\n",
    "    4. [Run Augmentation](#aug)\n",
    "    5. [See Augmented Dataset Properties](#statsAug)\n",
    "4. [Save Augmented Dataset](#saveAug)\n",
    "5. [Light curve comparison](#comparison)\n",
    "\n",
    "## 1. Import Packages<a name=\"imports\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-declaration",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ../snmachine/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-floating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snmachine import snaugment, sndata\n",
    "from utils.plasticc_pipeline import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removable-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False  # enable autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-interest",
   "metadata": {},
   "source": [
    "#### Aestetic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.3, style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-wages",
   "metadata": {},
   "source": [
    "## 2. Load Dataset<a name=\"loadData\"></a>\n",
    "\n",
    "First, **write** the path to the folder that contains the dataset we want to augment, `folder_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/share/hypatia/snmachine_resources/plasticc'\n",
    "folder_path = os.path.join(root_dir, 'data', 'raw_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-stationery",
   "metadata": {},
   "source": [
    "Then, **write** in `data_file_name` the name of the file where your dataset is saved.\n",
    "\n",
    "In this notebook we use the dataset saved in [2_preprocess_data]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-occasions",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_name = 'example_dataset_gapless50.pckl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-board",
   "metadata": {},
   "source": [
    "Load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(folder_path, data_file_name)\n",
    "dataset = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-calculation",
   "metadata": {},
   "source": [
    "### 2.1. GP Path<a name=\"oriGpPath\"></a>\n",
    "\n",
    "The GP augmentation uses the previously saved GPs, so **write** the path where they were saved. For help in fitting GPs to the dataset, follow [3_model_lightcurves]()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_saved_gps = os.path.join(folder_path, data_file_name[:-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-filing",
   "metadata": {},
   "source": [
    "## 3. Augment Dataset<a name=\"augData\"></a>\n",
    "\n",
    "Here we augment the data and make sure all the properties have the expected values.\n",
    "\n",
    "In the following sections we decide the following augmentation inputs: \n",
    "1. `objs_number_to_aug` : a dictionary specifying which events to augment and by how much.\n",
    "2. `choose_z` : function used to choose the new true redshift of the augmented events.\n",
    "3. `z_table` : dataset containing the spectroscopic and photometric redshift, and photometric redshift error of events; it is used to generate realistic augmented photometric redshifts.\n",
    "4. `max_duration` : maximum duration of the augmented light curves.\n",
    "5. `random_seed` : random seed used; saving this seed allows reproducible results.\n",
    "\n",
    "### 3.1. Choose the Events to Augment<a name=\"chooseEvent\"></a>\n",
    "\n",
    "**Write** in `aug_obj_names` a list containing all the events to augment. Here we will try to augment them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_obj_names = dataset.object_names  # try to augment all events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "played-bryan",
   "metadata": {},
   "source": [
    "**Create** a dictionary that associates to each event, the target number of synthetic events to create from it. Note that some augmentations will fail so this is not the final number of events. Additionally, each class has a different creation efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connected-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "is_to_aug = np.in1d(dataset.object_names, aug_obj_names)\n",
    "\n",
    "# Choose the target number of events in the augmented dataset. \n",
    "# Usually, only half of this number are accepted in the augmented dataset\n",
    "target_number_aug = np.sum(is_to_aug) * 2\n",
    "\n",
    "number_objs_per_label = collections.Counter(dataset.labels[is_to_aug])\n",
    "number_aug_per_label = target_number_aug//len(number_objs_per_label.keys())\n",
    "objs_number_to_aug = {}\n",
    "for label in number_objs_per_label.keys():\n",
    "    is_label = dataset.labels[is_to_aug] == label\n",
    "    aug_is_label_obj_names = aug_obj_names[is_label]\n",
    "    number_aug_per_obj = number_aug_per_label // np.sum(is_label)\n",
    "    number_extra_aug_per_obj = number_aug_per_label % np.sum(is_label)\n",
    "    extra_obj = np.random.choice(aug_is_label_obj_names, size=number_extra_aug_per_obj, \n",
    "                                 replace=False)\n",
    "    objs_number_to_aug.update({obj: number_aug_per_obj for obj in aug_is_label_obj_names})\n",
    "    objs_number_to_aug.update({obj: number_aug_per_obj+1 for obj in extra_obj})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-subscription",
   "metadata": {},
   "source": [
    "# ^ Add the balanced class option to the augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-editor",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'We aim to create up to {sum(objs_number_to_aug.values())} events.')  # confirm how many events to create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "actual-restoration",
   "metadata": {},
   "source": [
    "### 3.2. Choose the Redshift for Augmented Events<a name=\"chooseZ\"></a>\n",
    "\n",
    "We augment the dataset following a target redshift distribution for the _new spectroscopic redshifts_. You can either **define** the function here or **use** the ones defined in `snmachine`. See below for an example of such a function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-father",
   "metadata": {},
   "source": [
    "```python\n",
    "def choose_z_wfd(z_ori, pb_wavelengths, random_state):\n",
    "    \"\"\"Choose the new spectroscopic redshift for an WFD augmented event.\n",
    "\n",
    "    The new spectroscopic redshift is based on the redhsift of the original\n",
    "    event.\n",
    "    This target distribution of the redshift is class-agnostic and modeled\n",
    "    after the PLAsTiCC supernovae simulated in the Wide-Fast-Deep Survey.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    z_ori: float\n",
    "        Redshift of the original event.\n",
    "    pb_wavelengths: dict\n",
    "        Mapping between the passbands name and central wavelength.\n",
    "    random_state : numpy.random.mtrand.RandomState\n",
    "        Container for the slow Mersenne Twister pseudo-random number generator.\n",
    "        It allows reproducible results.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z_new: float\n",
    "        Redshift of the new event.\n",
    "    \"\"\"\n",
    "    z_min = max(10**(-4), (1 + z_ori) * (2 - pb_wavelengths['lsstz']\n",
    "                                         / pb_wavelengths['lssty'])**(-1) - 1)\n",
    "    z_max = ((1 + z_ori)\n",
    "             * (2 - pb_wavelengths['lsstg']/pb_wavelengths['lsstu'])**(-1) - 1)\n",
    "\n",
    "    log_z_star = random_state.triangular(left=np.log(z_min),\n",
    "                                         mode=np.log(z_min),\n",
    "                                         right=np.log(z_max))\n",
    "    z_new = - np.exp(log_z_star) + z_min + z_max\n",
    "\n",
    "    return z_new\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "choose_z = snaugment.choose_z_wfd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "answering-lightning",
   "metadata": {},
   "source": [
    "### 3.3. Choose the Photometric Redshift<a name=\"choosePhotoZ\"></a>\n",
    "\n",
    "In order to simulate realistic photometric redshifts for the synthetic events, following [Boone (2019)](https://iopscience.iop.org/article/10.3847/1538-3881/ab5182) we chose a random event from the test set events that had a spectroscopic redshift measurement, and calculated the difference between its spectroscopic and photometric redshifts. We then added this difference to the true redshift of the augmented event to generate a photometric redshift. \n",
    "\n",
    "**Add** such a dataset containing spectroscopic and photometric redshift, and photometric redshift error of events as `z_table`. If none is provided, a similar table is generated from the events in `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_file_name = 'example_test_dataset.pckl'\n",
    "test_data_path = os.path.join(folder_path, test_data_file_name)\n",
    "\n",
    "test_data = load_dataset(test_data_path)\n",
    "test_metadata = test_data.metadata\n",
    "\n",
    "# Discard the events without spectroscopic redshift; \n",
    "# these are encoded with `hostgal_specz` equal to -9\n",
    "z_table = test_metadata[test_metadata.hostgal_specz > -2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saved-exchange",
   "metadata": {},
   "source": [
    "### 3.4. Run Augmentation<a name=\"aug\"></a>\n",
    "\n",
    "In addition to the above inputs, we **chose** the random seed (`random_seed`) used to allow reproducible results and the maximum duration of the augmented light curves (`max_duration`).\n",
    "\n",
    "The value of `max_duration` must be higher than the maximum duration of any light curve in `dataset`. If none is provided, `max_duration` is set to the length of the longest event in `dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The longest event in `dataset` has {dataset.get_max_length():.2f} days.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42 \n",
    "max_duration = 277  # this is the length of the longest event in the PLAsTiCC SNe dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = snaugment.GPAugment(dataset=dataset, path_saved_gps=path_saved_gps, \n",
    "                          objs_number_to_aug=objs_number_to_aug, \n",
    "                          choose_z=choose_z, random_seed=random_seed, \n",
    "                          max_duration=max_duration, z_table=z_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.metadata['ddf'] = dataset.metadata['ddf_bool']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-hunger",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug.augment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-course",
   "metadata": {},
   "source": [
    "Go to:\n",
    "* [Index](#index)\n",
    "* [Save Augmented Dataset](#saveAug)\n",
    "  \n",
    "### 3.5. See Augmented Dataset Properties<a name=\"statsAug\"></a>\n",
    "\n",
    "Here we see some properties of the augmented dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:  # a test set was provided\n",
    "    test_metadata['target'] = test_metadata['true_target']\n",
    "    datasets_label = ['Original', 'Only Aug.', 'Test data']\n",
    "    datasets_metadata = [aug.dataset.metadata, aug.only_new_dataset.metadata, test_metadata]\n",
    "except NameError:   # no test set was provided\n",
    "    datasets_label = ['Original', 'Only Aug.']\n",
    "    datasets_metadata = [aug.dataset.metadata, aug.only_new_dataset.metadata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-latex",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The longest event in the augmented dataset (`aug.only_new_dataset`)'\n",
    "      f' has {aug.only_new_dataset.get_max_length():.2f} days.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'In total we generated {len(aug.only_new_dataset.object_names)} events.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-might",
   "metadata": {},
   "source": [
    "Note that we generated less events than our target number of augmented events. As mentioned in Section [Choose the Events to Augment](#chooseEvent), some of the augmentations fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{:^12}  {:^12}  {:^12}  {:^12}'.format('Dataset', 'total # objs', '# DDF objs', '% DDF objs'))\n",
    "print('-'*(12*4 + 3*2))\n",
    "for i in np.arange(len(datasets_label)):\n",
    "    is_ddf = datasets_metadata[i]['ddf'] == 1\n",
    "    number_total_objs = len(is_ddf)\n",
    "    number_ddf_objs = np.sum(is_ddf)\n",
    "    print('{:^12} {:^12} {:^12} {:^12.2f}'.format(\n",
    "        datasets_label[i], number_total_objs, number_ddf_objs, \n",
    "        number_ddf_objs/number_total_objs * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-slope",
   "metadata": {},
   "source": [
    "We now see the distribution of the photometric redshift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting choices\n",
    "diverg_color = sns.color_palette(\"Set2\", 3, desat=1)\n",
    "sn_type_color = {42: diverg_color[1], 62: diverg_color[0], 90: diverg_color[2]}\n",
    "sn_type_name = {42: 'SN II', 62: 'SN Ibc', 90: 'SN Ia'}\n",
    "unique_types = [90, 42, 62]\n",
    "datasets_ls = ['-', '-', '--']\n",
    "datasets_linewidth = [1, 3, 3]\n",
    "datasets_bw_adjust = [.3, .8, .8]\n",
    "\n",
    "# Plot the redshift distribution\n",
    "for sn_type in unique_types: # sns scale 2\n",
    "    plt.figure()\n",
    "    for i, metadata in enumerate(datasets_metadata):\n",
    "        label = datasets_label[i]\n",
    "        ls = datasets_ls[i]\n",
    "        linewidth = datasets_linewidth[i]\n",
    "        bw_adjust= datasets_bw_adjust[i]\n",
    "        is_sn_type = (metadata['target'] == sn_type)\n",
    "        sn_type_metadata = metadata[is_sn_type]\n",
    "        sns.distplot(a=sn_type_metadata['hostgal_photoz'], kde=True,\n",
    "                     hist=False, label=label, color=sn_type_color[sn_type],\n",
    "                     kde_kws={'linestyle':ls, 'linewidth':linewidth, \n",
    "                              'bw_adjust':bw_adjust})\n",
    "    sn_name = sn_type_name[sn_type]\n",
    "    plt.title(sn_name)\n",
    "    plt.xlim(-.1, 1.5)\n",
    "    plt.ylim(0, 3)\n",
    "    plt.xlabel('Photometric redshift')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend(handletextpad=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-variable",
   "metadata": {},
   "source": [
    "## 4. Save Augmented Dataset<a name=\"saveAug\"></a>\n",
    "\n",
    "Now, we save the `PlasticcData` instance containing only the augmented events. **Chose** a path to save (`folder_path_to_save`) and the name of the file (`file_name`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_to_save = folder_path\n",
    "file_name = 'example_dataset_aug.pckl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-palmer",
   "metadata": {},
   "source": [
    "At this point we could also choose to save only part of the augmented dataset. Here we save all the augmented events.\n",
    "\n",
    "**Add** an extra step to select your chosen subset. See the notebook [1_load_data]() for a tutorial on how to select a subset from a `PlasticcData` instance.\n",
    "\n",
    "Finally, save the `PlasticcData` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_aug_dataset = aug.only_new_dataset\n",
    "\n",
    "path_to_save = os.path.join(folder_path_to_save, file_name)\n",
    "with open(path_to_save, 'wb') as f:\n",
    "    pickle.dump(only_aug_dataset, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-luther",
   "metadata": {},
   "source": [
    "## 5. Light curve visualization<a name=\"see\"></a>\n",
    "\n",
    "Here we show the light curve of an event along with one of the synthetic events generated from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_show = '7033'\n",
    "sndata.PlasticcData.plot_obj_and_model(dataset.data[obj_show])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-rocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_aug_show = obj_show + '_aug0'\n",
    "sndata.PlasticcData.plot_obj_and_model(dataset.data[obj_show])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-freeware",
   "metadata": {},
   "source": [
    "[Go back to top.](#index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
